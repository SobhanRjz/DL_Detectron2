{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jTE3o393_hPx",
        "outputId": "10375cb4-294a-495b-f632-474143a2ea53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DL_Detectron2' already exists and is not an empty directory.\n",
            "/content/DL_Detectron2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SobhanRjz/DL_Detectron2.git\n",
        "%cd DL_Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: get from drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Then you can use standard file operations to access the files.\n",
        "# For example, to list the files in a folder:\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks\"\n"
      ],
      "metadata": {
        "id": "bFw3INkU_szs",
        "outputId": "eb2b3c99-7120-45cc-acd6-862344a69033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " images.rar   NeuralNetwork.ipynb  'Train_Detectron2_(7)_(9)_(1)_(6).ipynb'   Untitled0.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: makedir if not exist /content/DL_Detectron2/DataSets/images\n",
        "import os\n",
        "# Create the directory if it does not exist\n",
        "dir_path = \"/content/DL_Detectron2/DataSets/images\"\n",
        "if not os.path.exists(dir_path):\n",
        "\n",
        "    os.makedirs(dir_path)\n",
        "    print(f\"Directory '{dir_path}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Directory '{dir_path}' already exists.\")"
      ],
      "metadata": {
        "id": "vFY0nUot_wgP",
        "outputId": "b1cb611d-c2bb-4adc-f7e6-6240098710d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/DL_Detectron2/DataSets/images' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: unzip rar file\n",
        "\n",
        "!unrar x \"/content/drive/My Drive/Colab Notebooks/images.rar\" \"/content/DL_Detectron2/DataSets/images\"\n"
      ],
      "metadata": {
        "id": "T5FiH6pv_zcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5hTLerP-_hP3",
        "outputId": "e0607a86-6ba4-4664-8168-73ad0f421735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Using cached PyYAML-5.1.tar.gz (274 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 15837, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 15837 (delta 30), reused 16 (delta 15), pack-reused 15780 (from 2)\u001b[K\n",
            "Receiving objects: 100% (15837/15837), 6.40 MiB | 21.49 MiB/s, done.\n",
            "Resolving deltas: 100% (11537/11537), done.\n",
            "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (24.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs>=0.1.8) (6.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7) (3.1.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.5 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Look at training curves in tensorboard:\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "# Configure the logger\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,  # Set the logging level to INFO\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    force=True, # Resets any previous configuration\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout)  # Stream logs to Colab's cell output\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create logger instance\n",
        "logger = logging.getLogger()\n",
        "logger.info(\"Logger is configured!\")\n"
      ],
      "metadata": {
        "id": "kmIEmV2FG6nw",
        "outputId": "9f5b5102-ee62-4171-f72b-d78d9e3f3e5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-14 18:44:14,878 [INFO] Logger is configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JEKqi37CH5jJ",
        "outputId": "237f25b9-f655-4c3e-ef58-ea06bfc877ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing COCO JSON files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "logger.info(\"This is an INFO log.\")\n",
        "sys.stdout.flush()  # Ensure output is flushed to Colab's cell"
      ],
      "metadata": {
        "id": "ZLiBEl8DHKXx",
        "outputId": "f4b164de-9832-4e74-e059-f6a3b3c3503b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-14 18:44:28,801 [INFO] This is an INFO log.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ipykernel\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ],
      "metadata": {
        "id": "h-FkSP-dHwxz",
        "outputId": "2c7aa1cf-0d2b-4a9e-f5e1-2582916ad962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, comm, ipykernel\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comm-0.2.2 ipykernel-6.29.5 jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "# After configuring the logger\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.info(\"Processing COCO JSON files...\")\n",
        "sys.stdout.flush()  # Ensure logs are flushed to the notebook output"
      ],
      "metadata": {
        "id": "lkQkW9LmHCEf",
        "outputId": "049affd5-c96e-4612-f780-582ea7b80016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-14 18:45:23,201 [INFO] Processing COCO JSON files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LU-G9Rg0_hP3",
        "outputId": "ddb71b2d-0215-4958-8b9f-0e36f3d3b8ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detectron2 version: 0.6\n"
          ]
        }
      ],
      "source": [
        "import detectron2\n",
        "print(f\"Detectron2 version: {detectron2.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ez5WxxkF_hP4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "# Get the parent directory path\n",
        "parent_dir = os.path.dirname(os.getcwd())\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.append(parent_dir)\n",
        "\n",
        "\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from Config.basic_config import BASE_PATH, DATA_PATH, OUTPUT_PATH, DEVICE\n",
        "from Config.basic_config import detectron2_logger as logger\n",
        "from Config.detectron2_config import DetectronConfig\n",
        "from Config.dataset_config import DatasetConfig\n",
        "from PreProcess.preprocess_COCO import COCOJsonProcessor\n",
        "from Train import mainTrain\n",
        "from detectron2.engine import launch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pnI0EmQp_hP4",
        "outputId": "3ae9b191-e2f4-4f85-dafc-b58a7ec93503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DL_Detectron2/DataSets/images'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gY3IvD0y_hP5",
        "outputId": "54afa3e6-e870-4fcb-8573-700a2b09ba2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['coco_2014_train', 'coco_2014_val', 'coco_2014_minival', 'coco_2014_valminusminival', 'coco_2017_train', 'coco_2017_val', 'coco_2017_test', 'coco_2017_test-dev', 'coco_2017_val_100', 'keypoints_coco_2014_train', 'keypoints_coco_2014_val', 'keypoints_coco_2014_minival', 'keypoints_coco_2014_valminusminival', 'keypoints_coco_2017_train', 'keypoints_coco_2017_val', 'keypoints_coco_2017_val_100', 'coco_2017_train_panoptic_separated', 'coco_2017_train_panoptic_stuffonly', 'coco_2017_train_panoptic', 'coco_2017_val_panoptic_separated', 'coco_2017_val_panoptic_stuffonly', 'coco_2017_val_panoptic', 'coco_2017_val_100_panoptic_separated', 'coco_2017_val_100_panoptic_stuffonly', 'coco_2017_val_100_panoptic', 'lvis_v1_train', 'lvis_v1_val', 'lvis_v1_test_dev', 'lvis_v1_test_challenge', 'lvis_v0.5_train', 'lvis_v0.5_val', 'lvis_v0.5_val_rand_100', 'lvis_v0.5_test', 'lvis_v0.5_train_cocofied', 'lvis_v0.5_val_cocofied', 'cityscapes_fine_instance_seg_train', 'cityscapes_fine_sem_seg_train', 'cityscapes_fine_instance_seg_val', 'cityscapes_fine_sem_seg_val', 'cityscapes_fine_instance_seg_test', 'cityscapes_fine_sem_seg_test', 'cityscapes_fine_panoptic_train', 'cityscapes_fine_panoptic_val', 'voc_2007_trainval', 'voc_2007_train', 'voc_2007_val', 'voc_2007_test', 'voc_2012_trainval', 'voc_2012_train', 'voc_2012_val', 'ade20k_sem_seg_train', 'ade20k_sem_seg_val', 'my_dataset_train', 'my_dataset_valid', 'my_dataset_test']\n",
            "['coco_2014_train', 'coco_2014_val', 'coco_2014_minival', 'coco_2014_valminusminival', 'coco_2017_train', 'coco_2017_val', 'coco_2017_test', 'coco_2017_test-dev', 'coco_2017_val_100', 'keypoints_coco_2014_train', 'keypoints_coco_2014_val', 'keypoints_coco_2014_minival', 'keypoints_coco_2014_valminusminival', 'keypoints_coco_2017_train', 'keypoints_coco_2017_val', 'keypoints_coco_2017_val_100', 'coco_2017_train_panoptic_separated', 'coco_2017_train_panoptic_stuffonly', 'coco_2017_train_panoptic', 'coco_2017_val_panoptic_separated', 'coco_2017_val_panoptic_stuffonly', 'coco_2017_val_panoptic', 'coco_2017_val_100_panoptic_separated', 'coco_2017_val_100_panoptic_stuffonly', 'coco_2017_val_100_panoptic', 'lvis_v1_train', 'lvis_v1_val', 'lvis_v1_test_dev', 'lvis_v1_test_challenge', 'lvis_v0.5_train', 'lvis_v0.5_val', 'lvis_v0.5_val_rand_100', 'lvis_v0.5_test', 'lvis_v0.5_train_cocofied', 'lvis_v0.5_val_cocofied', 'cityscapes_fine_instance_seg_train', 'cityscapes_fine_sem_seg_train', 'cityscapes_fine_instance_seg_val', 'cityscapes_fine_sem_seg_val', 'cityscapes_fine_instance_seg_test', 'cityscapes_fine_sem_seg_test', 'cityscapes_fine_panoptic_train', 'cityscapes_fine_panoptic_val', 'voc_2007_trainval', 'voc_2007_train', 'voc_2007_val', 'voc_2007_test', 'voc_2012_trainval', 'voc_2012_train', 'voc_2012_val', 'ade20k_sem_seg_train', 'ade20k_sem_seg_val', 'my_dataset_train', 'my_dataset_valid', 'my_dataset_test']\n"
          ]
        }
      ],
      "source": [
        "# Use pathlib for more robust path handling\n",
        "json_paths = [\n",
        "    Path(DATA_PATH) / split / \"_annotations.coco.json\"\n",
        "    for split in [\"train\", \"test\", \"valid\"]\n",
        "]\n",
        "\n",
        "logger.info(\"Processing COCO JSON files...\")\n",
        "# coco_processor = COCOJsonProcessor([str(p) for p in json_paths])\n",
        "# coco_processor.process_files()\n",
        "\n",
        "logger.info(\"Registering datasets...\")\n",
        "DatasetConfig().register_datasets()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fsUZN1Xv_hP5"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
        "metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pLWU4MeA_hP5",
        "outputId": "260fff15-98fc-4dac-ae1d-252309b7b910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[156.85613942 426.09218377]\n",
            " [ 73.3173741   80.54901604]\n",
            " [410.20789239 240.90629763]\n",
            " [102.14131531 212.40040423]\n",
            " [212.87008804 117.50150553]]\n",
            "Calculated Anchor Ratios: [2.17276078 6.31717508 0.4676243  3.73976146 1.15638598]\n",
            "Adjusting anchor sizes from 5 to match 4 IN_FEATURES.\n",
            "Total Iterations: 24.6240234375\n",
            "Configuration saved to /content/DL_Detectron2/output/mask_rcnn_X_101_32x8d_FPN_3x.yaml\n"
          ]
        }
      ],
      "source": [
        "def setup_training():\n",
        "    \"\"\"Configure training settings and get GPU count\"\"\"\n",
        "    logger.info(\"Loading Detectron2 configuration...\")\n",
        "\n",
        "\n",
        "    detectron_config = DetectronConfig()\n",
        "    cfg = detectron_config.get_cfg()\n",
        "\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    logger.info(f\"Number of GPUs available: {num_gpus}\")\n",
        "\n",
        "    return cfg, num_gpus\n",
        "# Setup training configuration\n",
        "cfg, num_gpus = setup_training()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "# Make the output scrollable\n",
        "display(HTML(\"<style>.output_scroll { height: 400px !important; overflow: auto; }</style>\"))\n"
      ],
      "metadata": {
        "id": "eX0Scn7dFy-4",
        "outputId": "845da4f8-a021-416b-8d9e-d4a4f3320b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.output_scroll { height: 400px !important; overflow: auto; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjakzFOx_hP6",
        "outputId": "48da8298-29b2-4c48-ad2c-63b38f573e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-14 18:45:43,564 [INFO] Launching training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.output_scroll { height: 400px !important; overflow: auto; }</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-14 18:45:43,568 [INFO] Initializing default trainer...\n",
            "2025-01-14 18:45:45,260 [INFO] Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2025-01-14 18:45:45,262 [INFO] Starting training...\n",
            "2025-01-14 18:45:45,263 [INFO] Removed TensorBoard event file: /content/DL_Detectron2/output/events.out.tfevents.1736879626.3e3eb63331fa.5390.6\n",
            "2025-01-14 18:45:45,264 [INFO] Removed TensorBoard event file: /content/DL_Detectron2/output/events.out.tfevents.1736879635.3e3eb63331fa.5390.7\n",
            "2025-01-14 18:45:45,269 [INFO] [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl ...\n",
            "2025-01-14 18:45:45,270 [INFO] [Checkpointer] Loading from /root/.torch/iopath_cache/detectron2/ImageNetPretrained/FAIR/X-101-32x8d.pkl ...\n",
            "2025-01-14 18:45:45,379 [INFO] Renaming Caffe2 weights ......\n",
            "2025-01-14 18:45:45,552 [INFO] Following weights matched with submodule backbone.bottom_up - Total num: 105\n",
            "2025-01-14 18:45:45,675 [WARNING] Some model parameters or buffers are not found in the checkpoint:\n",
            "backbone.fpn_lateral2.{bias, weight}\n",
            "backbone.fpn_lateral3.{bias, weight}\n",
            "backbone.fpn_lateral4.{bias, weight}\n",
            "backbone.fpn_lateral5.{bias, weight}\n",
            "backbone.fpn_output2.{bias, weight}\n",
            "backbone.fpn_output3.{bias, weight}\n",
            "backbone.fpn_output4.{bias, weight}\n",
            "backbone.fpn_output5.{bias, weight}\n",
            "proposal_generator.rpn_head.anchor_deltas.{bias, weight}\n",
            "proposal_generator.rpn_head.conv.{bias, weight}\n",
            "proposal_generator.rpn_head.objectness_logits.{bias, weight}\n",
            "roi_heads.box_head.fc1.{bias, weight}\n",
            "roi_heads.box_head.fc2.{bias, weight}\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.deconv.{bias, weight}\n",
            "roi_heads.mask_head.mask_fcn1.{bias, weight}\n",
            "roi_heads.mask_head.mask_fcn2.{bias, weight}\n",
            "roi_heads.mask_head.mask_fcn3.{bias, weight}\n",
            "roi_heads.mask_head.mask_fcn4.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n",
            "2025-01-14 18:45:45,676 [WARNING] The checkpoint state_dict contains keys that are not used by the model:\n",
            "  linear.{bias, weight}\n",
            "2025-01-14 18:45:46,828 [INFO] Loading /content/DL_Detectron2/DataSets/images/train/_annotations.coco.json takes 1.15 seconds.\n",
            "2025-01-14 18:45:46,835 [INFO] Loaded 3362 images in COCO format from /content/DL_Detectron2/DataSets/images/train/_annotations.coco.json\n",
            "2025-01-14 18:45:46,877 [INFO] Removed 0 images with no usable annotations. 3362 images left.\n",
            "2025-01-14 18:45:46,988 [INFO] [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.8, 0.8]), ResizeShortestEdge(short_edge_length=(300, 400, 500), max_size=800, sample_style='choice'), RandomFlip()]\n",
            "2025-01-14 18:45:46,989 [INFO] Using training sampler RepeatFactorTrainingSampler\n",
            "2025-01-14 18:45:46,993 [INFO] Cat ID 0: freq=0.43, rep=1.00\n",
            "2025-01-14 18:45:46,996 [INFO] Cat ID 1: freq=0.24, rep=1.00\n",
            "2025-01-14 18:45:46,996 [INFO] Cat ID 2: freq=0.19, rep=1.00\n",
            "2025-01-14 18:45:46,997 [INFO] Cat ID 3: freq=0.08, rep=1.12\n",
            "2025-01-14 18:45:47,000 [INFO] Cat ID 4: freq=0.12, rep=1.00\n",
            "2025-01-14 18:45:47,000 [INFO] Cat ID 5: freq=0.27, rep=1.00\n",
            "2025-01-14 18:45:47,001 [INFO] Cat ID 6: freq=0.21, rep=1.00\n",
            "2025-01-14 18:45:47,002 [INFO] Cat ID 7: freq=0.09, rep=1.07\n",
            "2025-01-14 18:45:47,010 [INFO] Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "2025-01-14 18:45:47,010 [INFO] Serializing 3362 elements to byte tensors and concatenating them all ...\n",
            "2025-01-14 18:45:47,131 [INFO] Serialized dataset takes 15.44 MiB\n",
            "2025-01-14 18:45:47,133 [INFO] Making batched data loader with batch_size=8\n",
            "2025-01-14 18:45:47,176 [INFO] Starting training from iteration 0\n",
            "2025-01-14 18:45:53,589 [INFO]  iter: 19  total_loss: 3.468  loss_cls: 1.996  loss_box_reg: 0.01732  loss_mask: 0.6921  loss_rpn_cls: 0.7092  loss_rpn_loc: 0.03349     lr: 1.9981e-05  max_mem: 19290M\n",
            "2025-01-14 18:45:59,609 [INFO]  eta: 2:30:18  iter: 39  total_loss: 1.638  loss_cls: 0.2008  loss_box_reg: 0.02319  loss_mask: 0.6921  loss_rpn_cls: 0.686  loss_rpn_loc: 0.03365     lr: 3.9961e-05  max_mem: 19290M\n",
            "2025-01-14 18:46:06,648 [INFO]  eta: 2:55:36  iter: 59  total_loss: 1.595  loss_cls: 0.1888  loss_box_reg: 0.04837  loss_mask: 0.691  loss_rpn_cls: 0.6322  loss_rpn_loc: 0.02784     lr: 5.9941e-05  max_mem: 19290M\n",
            "2025-01-14 18:46:12,995 [INFO]  eta: 2:38:15  iter: 79  total_loss: 1.545  loss_cls: 0.2172  loss_box_reg: 0.06493  loss_mask: 0.6886  loss_rpn_cls: 0.5529  loss_rpn_loc: 0.03066     lr: 7.9921e-05  max_mem: 19290M\n",
            "2025-01-14 18:46:19,463 [INFO]  eta: 2:41:10  iter: 99  total_loss: 1.457  loss_cls: 0.2089  loss_box_reg: 0.06731  loss_mask: 0.6865  loss_rpn_cls: 0.4478  loss_rpn_loc: 0.02736     lr: 9.9901e-05  max_mem: 19290M\n",
            "2025-01-14 18:46:25,984 [INFO]  eta: 2:42:22  iter: 119  total_loss: 1.296  loss_cls: 0.1783  loss_box_reg: 0.07821  loss_mask: 0.6805  loss_rpn_cls: 0.3296  loss_rpn_loc: 0.03989     lr: 0.00011988  max_mem: 19290M\n",
            "2025-01-14 18:46:32,285 [INFO]  eta: 2:36:47  iter: 139  total_loss: 1.176  loss_cls: 0.1844  loss_box_reg: 0.07057  loss_mask: 0.6806  loss_rpn_cls: 0.2303  loss_rpn_loc: 0.03344     lr: 0.00013986  max_mem: 19290M\n",
            "2025-01-14 18:46:38,912 [INFO]  eta: 2:44:47  iter: 159  total_loss: 1.18  loss_cls: 0.21  loss_box_reg: 0.1021  loss_mask: 0.6786  loss_rpn_cls: 0.1705  loss_rpn_loc: 0.0372     lr: 0.00015984  max_mem: 19290M\n",
            "2025-01-14 18:46:45,472 [INFO]  eta: 2:43:00  iter: 179  total_loss: 1.095  loss_cls: 0.1623  loss_box_reg: 0.0768  loss_mask: 0.6744  loss_rpn_cls: 0.1324  loss_rpn_loc: 0.02759     lr: 0.00017982  max_mem: 19290M\n",
            "2025-01-14 18:46:52,530 [INFO]  eta: 2:55:16  iter: 199  total_loss: 1.151  loss_cls: 0.1946  loss_box_reg: 0.09761  loss_mask: 0.6663  loss_rpn_cls: 0.1528  loss_rpn_loc: 0.04228     lr: 0.0001998  max_mem: 19290M\n",
            "2025-01-14 18:46:59,365 [INFO]  eta: 2:49:36  iter: 219  total_loss: 1.099  loss_cls: 0.1761  loss_box_reg: 0.08338  loss_mask: 0.6649  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.02834     lr: 0.00021978  max_mem: 19290M\n",
            "2025-01-14 18:47:06,016 [INFO]  eta: 2:44:57  iter: 239  total_loss: 1.054  loss_cls: 0.1535  loss_box_reg: 0.07675  loss_mask: 0.6716  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.02969     lr: 0.00023976  max_mem: 19290M\n",
            "2025-01-14 18:47:12,723 [INFO]  eta: 2:46:13  iter: 259  total_loss: 1.05  loss_cls: 0.1564  loss_box_reg: 0.07722  loss_mask: 0.6661  loss_rpn_cls: 0.1157  loss_rpn_loc: 0.02995     lr: 0.00025974  max_mem: 19290M\n",
            "2025-01-14 18:47:19,473 [INFO]  eta: 2:47:10  iter: 279  total_loss: 1.084  loss_cls: 0.1646  loss_box_reg: 0.08784  loss_mask: 0.6695  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.02584     lr: 0.00027972  max_mem: 19290M\n",
            "2025-01-14 18:47:26,198 [INFO]  eta: 2:46:26  iter: 299  total_loss: 1.06  loss_cls: 0.1654  loss_box_reg: 0.09132  loss_mask: 0.6755  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.02826     lr: 0.0002997  max_mem: 19290M\n",
            "2025-01-14 18:47:32,871 [INFO]  eta: 2:45:03  iter: 319  total_loss: 1.081  loss_cls: 0.1688  loss_box_reg: 0.09396  loss_mask: 0.6705  loss_rpn_cls: 0.1257  loss_rpn_loc: 0.04193     lr: 0.00031968  max_mem: 19290M\n",
            "2025-01-14 18:47:40,152 [INFO]  eta: 2:59:56  iter: 339  total_loss: 1.086  loss_cls: 0.1686  loss_box_reg: 0.1005  loss_mask: 0.6638  loss_rpn_cls: 0.1219  loss_rpn_loc: 0.03373     lr: 0.00033966  max_mem: 19290M\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Launching training...\")\n",
        "# Set a custom height for the output\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Make the output scrollable\n",
        "display(HTML(\"<style>.output_scroll { height: 400px !important; overflow: auto; }</style>\"))\n",
        "\n",
        "\n",
        "mainTrain(cfg, \"default\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Vu-7I-_hP6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}